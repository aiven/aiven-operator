apiVersion: apiextensions.k8s.io/v1beta1
kind: CustomResourceDefinition
metadata:
  annotations:
    controller-gen.kubebuilder.io/version: v0.3.0
  creationTimestamp: null
  name: kafkas.k8s-operator.aiven.io
spec:
  group: k8s-operator.aiven.io
  names:
    kind: Kafka
    listKind: KafkaList
    plural: kafkas
    singular: kafka
  scope: Namespaced
  subresources:
    status: {}
  validation:
    openAPIV3Schema:
      description: Kafka is the Schema for the kafkas API
      properties:
        apiVersion:
          description: 'APIVersion defines the versioned schema of this representation of an object. Servers should convert recognized schemas to the latest internal value, and may reject unrecognized values. More info: https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#resources'
          type: string
        kind:
          description: 'Kind is a string value representing the REST resource this object represents. Servers may infer this from the endpoint the client submits requests to. Cannot be updated. In CamelCase. More info: https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#types-kinds'
          type: string
        metadata:
          type: object
        spec:
          description: KafkaSpec defines the desired state of Kafka
          properties:
            cloud_name:
              description: Cloud the service runs in.
              maxLength: 256
              type: string
            kafka_user_config:
              description: Kafka specific user configuration options
              properties:
                ip_filter:
                  description: IP filter Allow incoming connections from CIDR address block, e.g. '10.20.0.0/16'
                  items:
                    type: string
                  type: array
                kafka:
                  description: Kafka broker configuration values
                  properties:
                    auto_create_topics_enable:
                      description: auto.create.topics.enable Enable auto creation of topics
                      type: boolean
                    compression_type:
                      description: compression.type Specify the final compression type for a given topic. This configuration accepts the standard compression codecs ('gzip', 'snappy', 'lz4', 'zstd'). It additionally accepts 'uncompressed' which is equivalent to no compression; and 'producer' which means retain the original compression codec set by the producer.
                      enum:
                      - gzip
                      - snappy
                      - lz4
                      - zstd
                      - uncompressed
                      - producer
                      type: string
                    connections_max_idle_ms:
                      description: 'connections.max.idle.ms Idle connections timeout: the server socket processor threads close the connections that idle for longer than this.'
                      format: int64
                      maximum: 3600000
                      minimum: 1000
                      type: integer
                    default_replication_factor:
                      description: default.replication.factor Replication factor for autocreated topics
                      format: int64
                      maximum: 10
                      minimum: 1
                      type: integer
                    group_max_session_timeout_ms:
                      description: group.max.session.timeout.ms The maximum allowed session timeout for registered consumers. Longer timeouts give consumers more time to process messages in between heartbeats at the cost of a longer time to detect failures.
                      format: int64
                      maximum: 1800000
                      minimum: 0
                      type: integer
                    group_min_session_timeout_ms:
                      description: group.min.session.timeout.ms The minimum allowed session timeout for registered consumers. Longer timeouts give consumers more time to process messages in between heartbeats at the cost of a longer time to detect failures.
                      format: int64
                      maximum: 60000
                      minimum: 0
                      type: integer
                    log_cleaner_delete_retention_ms:
                      description: log.cleaner.delete.retention.ms How long are delete records retained?
                      format: int64
                      maximum: 315569260000
                      minimum: 0
                      type: integer
                    log_cleaner_max_compaction_lag_ms:
                      description: log.cleaner.max.compaction.lag.ms The maximum amount of time message will remain uncompacted. Only applicable for logs that are being compacted
                      format: int64
                      minimum: 30000
                      type: integer
                    log_cleaner_min_cleanable_ratio:
                      description: log.cleaner.min.cleanable.ratio Controls log compactor frequency. Larger value means more frequent compactions but also more space wasted for logs. Consider setting log.cleaner.max.compaction.lag.ms to enforce compactions sooner, instead of setting a very high value for this option.
                      format: int64
                      maximum: 1
                      minimum: 0
                      type: integer
                    log_cleaner_min_compaction_lag_ms:
                      description: log.cleaner.min.compaction.lag.ms The minimum time a message will remain uncompacted in the log. Only applicable for logs that are being compacted.
                      format: int64
                      minimum: 0
                      type: integer
                    log_cleanup_policy:
                      description: log.cleanup.policy The default cleanup policy for segments beyond the retention window
                      enum:
                      - compact
                      - delete
                      type: string
                    log_flush_interval_messages:
                      description: log.flush.interval.messages The number of messages accumulated on a log partition before messages are flushed to disk
                      format: int64
                      minimum: 1
                      type: integer
                    log_flush_interval_ms:
                      description: log.flush.interval.ms The maximum time in ms that a message in any topic is kept in memory before flushed to disk. If not set, the value in log.flush.scheduler.interval.ms is used
                      format: int64
                      minimum: 0
                      type: integer
                    log_index_interval_bytes:
                      description: log.index.interval.bytes The interval with which Kafka adds an entry to the offset index
                      format: int64
                      maximum: 104857600
                      minimum: 0
                      type: integer
                    log_index_size_max_bytes:
                      description: log.index.size.max.bytes The maximum size in bytes of the offset index
                      format: int64
                      maximum: 104857600
                      minimum: 1048576
                      type: integer
                    log_message_downconversion_enable:
                      description: log.message.downconversion.enable This configuration controls whether down-conversion of message formats is enabled to satisfy consume requests.
                      type: boolean
                    log_message_timestamp_difference_max_ms:
                      description: log.message.timestamp.difference.max.ms The maximum difference allowed between the timestamp when a broker receives a message and the timestamp specified in the message
                      format: int64
                      minimum: 0
                      type: integer
                    log_message_timestamp_type:
                      description: log.message.timestamp.type Define whether the timestamp in the message is message create time or log append time.
                      enum:
                      - CreateTime
                      - LogAppendTime
                      type: string
                    log_preallocate:
                      description: log.preallocate Should pre allocate file when create new segment?
                      type: boolean
                    log_retention_bytes:
                      description: log.retention.bytes The maximum size of the log before deleting messages
                      format: int64
                      type: integer
                    log_retention_hours:
                      description: log.retention.hours The number of hours to keep a log file before deleting it
                      format: int64
                      maximum: 2147483647
                      type: integer
                    log_retention_ms:
                      description: log.retention.ms The number of milliseconds to keep a log file before deleting it (in milliseconds), If not set, the value in log.retention.minutes is used. If set to -1, no time limit is applied.
                      format: int64
                      type: integer
                    log_roll_jitter_ms:
                      description: log.roll.jitter.ms The maximum jitter to subtract from logRollTimeMillis (in milliseconds). If not set, the value in log.roll.jitter.hours is used
                      format: int64
                      minimum: 0
                      type: integer
                    log_roll_ms:
                      description: log.roll.ms The maximum time before a new log segment is rolled out (in milliseconds).
                      format: int64
                      minimum: 1
                      type: integer
                    log_segment_bytes:
                      description: log.segment.bytes The maximum size of a single log file
                      format: int64
                      maximum: 1073741824
                      minimum: 10485760
                      type: integer
                    log_segment_delete_delay_ms:
                      description: log.segment.delete.delay.ms The amount of time to wait before deleting a file from the filesystem
                      format: int64
                      maximum: 3600000
                      minimum: 0
                      type: integer
                    max_connections_per_ip:
                      description: max.connections.per.ip The maximum number of connections allowed from each ip address (defaults to 2147483647).
                      format: int64
                      maximum: 2147483647
                      minimum: 256
                      type: integer
                    max_incremental_fetch_session_cache_slots:
                      description: max.incremental.fetch.session.cache.slots The maximum number of incremental fetch sessions that the broker will maintain.
                      format: int64
                      maximum: 10000
                      minimum: 1000
                      type: integer
                    message_max_bytes:
                      description: message.max.bytes The maximum size of message that the server can receive.
                      format: int64
                      maximum: 100001200
                      minimum: 0
                      type: integer
                    min_insync_replicas:
                      description: min.insync.replicas When a producer sets acks to 'all' (or '-1'), min.insync.replicas specifies the minimum number of replicas that must acknowledge a write for the write to be considered successful.
                      format: int64
                      maximum: 7
                      minimum: 1
                      type: integer
                    num_partitions:
                      description: num.partitions Number of partitions for autocreated topics
                      format: int64
                      maximum: 1000
                      minimum: 1
                      type: integer
                    offsets_retention_minutes:
                      description: offsets.retention.minutes Log retention window in minutes for offsets topic
                      format: int64
                      maximum: 2147483647
                      minimum: 1
                      type: integer
                    producer_purgatory_purge_interval_requests:
                      description: producer.purgatory.purge.interval.requests The purge interval (in number of requests) of the producer request purgatory(defaults to 1000).
                      format: int64
                      maximum: 10000
                      minimum: 10
                      type: integer
                    replica_fetch_max_bytes:
                      description: replica.fetch.max.bytes The number of bytes of messages to attempt to fetch for each partition (defaults to 1048576). This is not an absolute maximum, if the first record batch in the first non-empty partition of the fetch is larger than this value, the record batch will still be returned to ensure that progress can be made.
                      format: int64
                      maximum: 104857600
                      minimum: 1048576
                      type: integer
                    replica_fetch_response_max_bytes:
                      description: replica.fetch.response.max.bytes Maximum bytes expected for the entire fetch response (defaults to 10485760). Records are fetched in batches, and if the first record batch in the first non-empty partition of the fetch is larger than this value, the record batch will still be returned to ensure that progress can be made. As such, this is not an absolute maximum.
                      format: int64
                      maximum: 1048576000
                      minimum: 10485760
                      type: integer
                    socket_request_max_bytes:
                      description: socket.request.max.bytes The maximum number of bytes in a socket request (defaults to 104857600).
                      format: int64
                      maximum: 209715200
                      minimum: 10485760
                      type: integer
                  type: object
                kafka_authentication_methods:
                  description: Kafka authentication methods
                  properties:
                    certificate:
                      description: Enable certificate/SSL authentication
                      type: boolean
                    sasl:
                      description: Enable SASL authentication
                      type: boolean
                  type: object
                kafka_connect:
                  description: Enable Kafka Connect service
                  type: boolean
                kafka_connect_user_config:
                  description: Kafka Connect configuration values
                  properties:
                    connector_client_config_override_policy:
                      description: Client config override policy Defines what client configurations can be overridden by the connector. Default is None
                      enum:
                      - None
                      - All
                      type: string
                    consumer_auto_offset_reset:
                      description: Consumer auto offset reset What to do when there is no initial offset in Kafka or if the current offset does not exist any more on the server. Default is earliest
                      enum:
                      - earliest
                      - latest
                      type: string
                    consumer_fetch_max_bytes:
                      description: The maximum amount of data the server should return for a fetch request Records are fetched in batches by the consumer, and if the first record batch in the first non-empty partition of the fetch is larger than this value, the record batch will still be returned to ensure that the consumer can make progress. As such, this is not a absolute maximum.
                      format: int64
                      maximum: 104857600
                      minimum: 1048576
                      type: integer
                    consumer_isolation_level:
                      description: Consumer isolation level Transaction read isolation level. read_uncommitted is the default, but read_committed can be used if consume-exactly-once behavior is desired.
                      enum:
                      - read_uncommitted
                      - read_committed
                      type: string
                    consumer_max_partition_fetch_bytes:
                      description: The maximum amount of data per-partition the server will return. Records are fetched in batches by the consumer.If the first record batch in the first non-empty partition of the fetch is larger than this limit, the batch will still be returned to ensure that the consumer can make progress.
                      format: int64
                      maximum: 104857600
                      minimum: 1048576
                      type: integer
                    consumer_max_poll_interval_ms:
                      description: The maximum delay between polls when using consumer group management The maximum delay in milliseconds between invocations of poll() when using consumer group management (defaults to 300000).
                      format: int64
                      maximum: 2147483647
                      minimum: 1
                      type: integer
                    consumer_max_poll_records:
                      description: The maximum number of records returned by a single poll The maximum number of records returned in a single call to poll() (defaults to 500).
                      format: int64
                      maximum: 10000
                      minimum: 1
                      type: integer
                    offset_flush_interval_ms:
                      description: The interval at which to try committing offsets for tasks The interval at which to try committing offsets for tasks (defaults to 60000).
                      format: int64
                      maximum: 100000000
                      minimum: 1
                      type: integer
                    offset_flush_timeout_ms:
                      description: Offset flush timeout Maximum number of milliseconds to wait for records to flush and partition offset data to be committed to offset storage before cancelling the process and restoring the offset data to be committed in a future attempt (defaults to 5000).
                      format: int64
                      maximum: 2147483647
                      minimum: 1
                      type: integer
                    producer_max_request_size:
                      description: The maximum size of a request in bytes This setting will limit the number of record batches the producer will send in a single request to avoid sending huge requests.
                      format: int64
                      maximum: 10485760
                      minimum: 131072
                      type: integer
                    session_timeout_ms:
                      description: The timeout used to detect failures when using Kafka’s group management facilities The timeout in milliseconds used to detect failures when using Kafka’s group management facilities (defaults to 10000).
                      format: int64
                      maximum: 2147483647
                      minimum: 1
                      type: integer
                  type: object
                kafka_rest:
                  description: Enable Kafka-REST service
                  type: boolean
                kafka_rest_config:
                  description: Kafka REST configuration
                  properties:
                    consumer_enable_auto_commit:
                      description: consumer.enable.auto.commit If true the consumer's offset will be periodically committed to Kafka in the background
                      type: boolean
                    consumer_request_max_bytes:
                      description: consumer.request.max.bytes Maximum number of bytes in unencoded message keys and values by a single request
                      format: int64
                      maximum: 671088640
                      minimum: 0
                      type: integer
                    consumer_request_timeout_ms:
                      description: consumer.request.timeout.ms The maximum total time to wait for messages for a request if the maximum number of messages has not yet been reached
                      enum:
                      - 1000
                      - 15000
                      - 30000
                      format: int64
                      maximum: 30000
                      minimum: 1000
                      type: integer
                    custom_domain:
                      description: Custom domain Serve the web frontend using a custom CNAME pointing to the Aiven DNS name
                      maxLength: 255
                      type: string
                    producer_acks:
                      description: producer.acks The number of acknowledgments the producer requires the leader to have received before considering a request complete. If set to 'all' or '-1', the leader will wait for the full set of in-sync replicas to acknowledge the record.
                      enum:
                      - all
                      - "-1"
                      - 0
                      - 1
                      type: string
                    producer_linger_ms:
                      description: producer.linger.ms Wait for up to the given delay to allow batching records together
                      format: int64
                      maximum: 5000
                      minimum: 0
                      type: integer
                    public_access:
                      description: Allow access to selected service ports from the public Internet
                      properties:
                        kafka:
                          description: Allow clients to connect to kafka from the public internet for service nodes that are in a project VPC or another type of private network
                          type: boolean
                        kafka_connect:
                          description: Allow clients to connect to kafka_connect from the public internet for service nodes that are in a project VPC or another type of private network
                          type: boolean
                        kafka_rest:
                          description: Allow clients to connect to kafka_rest from the public internet for service nodes that are in a project VPC or another type of private network
                          type: boolean
                        prometheus:
                          description: Allow clients to connect to prometheus from the public internet for service nodes that are in a project VPC or another type of private network
                          type: boolean
                        schema_registry:
                          description: Allow clients to connect to schema_registry from the public internet for service nodes that are in a project VPC or another type of private network
                          type: boolean
                      type: object
                    simpleconsumer_pool_size_max:
                      description: simpleconsumer.pool.size.max Maximum number of SimpleConsumers that can be instantiated per broker
                      format: int64
                      maximum: 250
                      minimum: 10
                      type: integer
                  type: object
                kafka_version:
                  description: Kafka major version
                  enum:
                  - "1.0"
                  - "1.1"
                  - "2.0"
                  - "2.1"
                  - "2.2"
                  - "2.3"
                  - "2.4"
                  - "2.5"
                  - "2.6"
                  - "2.7"
                  type: string
                private_access:
                  description: Allow access to selected service ports from private networks
                  properties:
                    prometheus:
                      description: Allow clients to connect to prometheus with a DNS name that always resolves to the service's private IP addresses. Only available in certain network locations
                      type: boolean
                  type: object
                schema_registry:
                  description: Enable Schema-Registry service
                  type: boolean
                schema_registry_config:
                  description: Schema Registry configuration
                  properties:
                    leader_eligibility:
                      description: leader_eligibility If true, Karapace / Schema Registry on the service nodes can participate in leader election. It might be needed to disable this when the schemas topic is replicated to a secondary cluster and Karapace / Schema Registry there must not participate in leader election. Defaults to 'true'.
                      type: boolean
                    topic_name:
                      description: topic_name The durable single partition topic that acts as the durable log for the data. This topic must be compacted to avoid losing data due to retention policy. Please note that changing this configuration in an existing Schema Registry / Karapace setup leads to previous schemas being inaccessible, data encoded with them potentially unreadable and schema ID sequence put out of order. It's only possible to do the switch while Schema Registry / Karapace is disabled. Defaults to '_schemas'.
                      maxLength: 249
                      type: string
                  type: object
              type: object
            maintenance_window_dow:
              description: Day of week when maintenance operations should be performed. One monday, tuesday, wednesday, etc.
              enum:
              - monday
              - tuesday
              - wednesday
              - thursday
              - friday
              - saturday
              - sunday
              - never
              type: string
            maintenance_window_time:
              description: Time of day when maintenance operations should be performed. UTC time in HH:mm:ss format.
              maxLength: 8
              type: string
            plan:
              description: Subscription plan.
              maxLength: 128
              type: string
            project:
              description: Target project.
              format: ^[a-zA-Z0-9_-]*$
              maxLength: 63
              type: string
            project_vpc_id:
              description: Identifier of the VPC the service should be in, if any.
              maxLength: 36
              type: string
            service_name:
              description: Service name.
              maxLength: 63
              type: string
          required:
          - project
          - service_name
          type: object
        status:
          description: KafkaStatus defines the observed state of Kafka
          properties:
            cloud_name:
              description: Cloud the service runs in.
              maxLength: 256
              type: string
            kafka_user_config:
              description: Kafka specific user configuration options
              properties:
                ip_filter:
                  description: IP filter Allow incoming connections from CIDR address block, e.g. '10.20.0.0/16'
                  items:
                    type: string
                  type: array
                kafka:
                  description: Kafka broker configuration values
                  properties:
                    auto_create_topics_enable:
                      description: auto.create.topics.enable Enable auto creation of topics
                      type: boolean
                    compression_type:
                      description: compression.type Specify the final compression type for a given topic. This configuration accepts the standard compression codecs ('gzip', 'snappy', 'lz4', 'zstd'). It additionally accepts 'uncompressed' which is equivalent to no compression; and 'producer' which means retain the original compression codec set by the producer.
                      enum:
                      - gzip
                      - snappy
                      - lz4
                      - zstd
                      - uncompressed
                      - producer
                      type: string
                    connections_max_idle_ms:
                      description: 'connections.max.idle.ms Idle connections timeout: the server socket processor threads close the connections that idle for longer than this.'
                      format: int64
                      maximum: 3600000
                      minimum: 1000
                      type: integer
                    default_replication_factor:
                      description: default.replication.factor Replication factor for autocreated topics
                      format: int64
                      maximum: 10
                      minimum: 1
                      type: integer
                    group_max_session_timeout_ms:
                      description: group.max.session.timeout.ms The maximum allowed session timeout for registered consumers. Longer timeouts give consumers more time to process messages in between heartbeats at the cost of a longer time to detect failures.
                      format: int64
                      maximum: 1800000
                      minimum: 0
                      type: integer
                    group_min_session_timeout_ms:
                      description: group.min.session.timeout.ms The minimum allowed session timeout for registered consumers. Longer timeouts give consumers more time to process messages in between heartbeats at the cost of a longer time to detect failures.
                      format: int64
                      maximum: 60000
                      minimum: 0
                      type: integer
                    log_cleaner_delete_retention_ms:
                      description: log.cleaner.delete.retention.ms How long are delete records retained?
                      format: int64
                      maximum: 315569260000
                      minimum: 0
                      type: integer
                    log_cleaner_max_compaction_lag_ms:
                      description: log.cleaner.max.compaction.lag.ms The maximum amount of time message will remain uncompacted. Only applicable for logs that are being compacted
                      format: int64
                      minimum: 30000
                      type: integer
                    log_cleaner_min_cleanable_ratio:
                      description: log.cleaner.min.cleanable.ratio Controls log compactor frequency. Larger value means more frequent compactions but also more space wasted for logs. Consider setting log.cleaner.max.compaction.lag.ms to enforce compactions sooner, instead of setting a very high value for this option.
                      format: int64
                      maximum: 1
                      minimum: 0
                      type: integer
                    log_cleaner_min_compaction_lag_ms:
                      description: log.cleaner.min.compaction.lag.ms The minimum time a message will remain uncompacted in the log. Only applicable for logs that are being compacted.
                      format: int64
                      minimum: 0
                      type: integer
                    log_cleanup_policy:
                      description: log.cleanup.policy The default cleanup policy for segments beyond the retention window
                      enum:
                      - compact
                      - delete
                      type: string
                    log_flush_interval_messages:
                      description: log.flush.interval.messages The number of messages accumulated on a log partition before messages are flushed to disk
                      format: int64
                      minimum: 1
                      type: integer
                    log_flush_interval_ms:
                      description: log.flush.interval.ms The maximum time in ms that a message in any topic is kept in memory before flushed to disk. If not set, the value in log.flush.scheduler.interval.ms is used
                      format: int64
                      minimum: 0
                      type: integer
                    log_index_interval_bytes:
                      description: log.index.interval.bytes The interval with which Kafka adds an entry to the offset index
                      format: int64
                      maximum: 104857600
                      minimum: 0
                      type: integer
                    log_index_size_max_bytes:
                      description: log.index.size.max.bytes The maximum size in bytes of the offset index
                      format: int64
                      maximum: 104857600
                      minimum: 1048576
                      type: integer
                    log_message_downconversion_enable:
                      description: log.message.downconversion.enable This configuration controls whether down-conversion of message formats is enabled to satisfy consume requests.
                      type: boolean
                    log_message_timestamp_difference_max_ms:
                      description: log.message.timestamp.difference.max.ms The maximum difference allowed between the timestamp when a broker receives a message and the timestamp specified in the message
                      format: int64
                      minimum: 0
                      type: integer
                    log_message_timestamp_type:
                      description: log.message.timestamp.type Define whether the timestamp in the message is message create time or log append time.
                      enum:
                      - CreateTime
                      - LogAppendTime
                      type: string
                    log_preallocate:
                      description: log.preallocate Should pre allocate file when create new segment?
                      type: boolean
                    log_retention_bytes:
                      description: log.retention.bytes The maximum size of the log before deleting messages
                      format: int64
                      type: integer
                    log_retention_hours:
                      description: log.retention.hours The number of hours to keep a log file before deleting it
                      format: int64
                      maximum: 2147483647
                      type: integer
                    log_retention_ms:
                      description: log.retention.ms The number of milliseconds to keep a log file before deleting it (in milliseconds), If not set, the value in log.retention.minutes is used. If set to -1, no time limit is applied.
                      format: int64
                      type: integer
                    log_roll_jitter_ms:
                      description: log.roll.jitter.ms The maximum jitter to subtract from logRollTimeMillis (in milliseconds). If not set, the value in log.roll.jitter.hours is used
                      format: int64
                      minimum: 0
                      type: integer
                    log_roll_ms:
                      description: log.roll.ms The maximum time before a new log segment is rolled out (in milliseconds).
                      format: int64
                      minimum: 1
                      type: integer
                    log_segment_bytes:
                      description: log.segment.bytes The maximum size of a single log file
                      format: int64
                      maximum: 1073741824
                      minimum: 10485760
                      type: integer
                    log_segment_delete_delay_ms:
                      description: log.segment.delete.delay.ms The amount of time to wait before deleting a file from the filesystem
                      format: int64
                      maximum: 3600000
                      minimum: 0
                      type: integer
                    max_connections_per_ip:
                      description: max.connections.per.ip The maximum number of connections allowed from each ip address (defaults to 2147483647).
                      format: int64
                      maximum: 2147483647
                      minimum: 256
                      type: integer
                    max_incremental_fetch_session_cache_slots:
                      description: max.incremental.fetch.session.cache.slots The maximum number of incremental fetch sessions that the broker will maintain.
                      format: int64
                      maximum: 10000
                      minimum: 1000
                      type: integer
                    message_max_bytes:
                      description: message.max.bytes The maximum size of message that the server can receive.
                      format: int64
                      maximum: 100001200
                      minimum: 0
                      type: integer
                    min_insync_replicas:
                      description: min.insync.replicas When a producer sets acks to 'all' (or '-1'), min.insync.replicas specifies the minimum number of replicas that must acknowledge a write for the write to be considered successful.
                      format: int64
                      maximum: 7
                      minimum: 1
                      type: integer
                    num_partitions:
                      description: num.partitions Number of partitions for autocreated topics
                      format: int64
                      maximum: 1000
                      minimum: 1
                      type: integer
                    offsets_retention_minutes:
                      description: offsets.retention.minutes Log retention window in minutes for offsets topic
                      format: int64
                      maximum: 2147483647
                      minimum: 1
                      type: integer
                    producer_purgatory_purge_interval_requests:
                      description: producer.purgatory.purge.interval.requests The purge interval (in number of requests) of the producer request purgatory(defaults to 1000).
                      format: int64
                      maximum: 10000
                      minimum: 10
                      type: integer
                    replica_fetch_max_bytes:
                      description: replica.fetch.max.bytes The number of bytes of messages to attempt to fetch for each partition (defaults to 1048576). This is not an absolute maximum, if the first record batch in the first non-empty partition of the fetch is larger than this value, the record batch will still be returned to ensure that progress can be made.
                      format: int64
                      maximum: 104857600
                      minimum: 1048576
                      type: integer
                    replica_fetch_response_max_bytes:
                      description: replica.fetch.response.max.bytes Maximum bytes expected for the entire fetch response (defaults to 10485760). Records are fetched in batches, and if the first record batch in the first non-empty partition of the fetch is larger than this value, the record batch will still be returned to ensure that progress can be made. As such, this is not an absolute maximum.
                      format: int64
                      maximum: 1048576000
                      minimum: 10485760
                      type: integer
                    socket_request_max_bytes:
                      description: socket.request.max.bytes The maximum number of bytes in a socket request (defaults to 104857600).
                      format: int64
                      maximum: 209715200
                      minimum: 10485760
                      type: integer
                  type: object
                kafka_authentication_methods:
                  description: Kafka authentication methods
                  properties:
                    certificate:
                      description: Enable certificate/SSL authentication
                      type: boolean
                    sasl:
                      description: Enable SASL authentication
                      type: boolean
                  type: object
                kafka_connect:
                  description: Enable Kafka Connect service
                  type: boolean
                kafka_connect_user_config:
                  description: Kafka Connect configuration values
                  properties:
                    connector_client_config_override_policy:
                      description: Client config override policy Defines what client configurations can be overridden by the connector. Default is None
                      enum:
                      - None
                      - All
                      type: string
                    consumer_auto_offset_reset:
                      description: Consumer auto offset reset What to do when there is no initial offset in Kafka or if the current offset does not exist any more on the server. Default is earliest
                      enum:
                      - earliest
                      - latest
                      type: string
                    consumer_fetch_max_bytes:
                      description: The maximum amount of data the server should return for a fetch request Records are fetched in batches by the consumer, and if the first record batch in the first non-empty partition of the fetch is larger than this value, the record batch will still be returned to ensure that the consumer can make progress. As such, this is not a absolute maximum.
                      format: int64
                      maximum: 104857600
                      minimum: 1048576
                      type: integer
                    consumer_isolation_level:
                      description: Consumer isolation level Transaction read isolation level. read_uncommitted is the default, but read_committed can be used if consume-exactly-once behavior is desired.
                      enum:
                      - read_uncommitted
                      - read_committed
                      type: string
                    consumer_max_partition_fetch_bytes:
                      description: The maximum amount of data per-partition the server will return. Records are fetched in batches by the consumer.If the first record batch in the first non-empty partition of the fetch is larger than this limit, the batch will still be returned to ensure that the consumer can make progress.
                      format: int64
                      maximum: 104857600
                      minimum: 1048576
                      type: integer
                    consumer_max_poll_interval_ms:
                      description: The maximum delay between polls when using consumer group management The maximum delay in milliseconds between invocations of poll() when using consumer group management (defaults to 300000).
                      format: int64
                      maximum: 2147483647
                      minimum: 1
                      type: integer
                    consumer_max_poll_records:
                      description: The maximum number of records returned by a single poll The maximum number of records returned in a single call to poll() (defaults to 500).
                      format: int64
                      maximum: 10000
                      minimum: 1
                      type: integer
                    offset_flush_interval_ms:
                      description: The interval at which to try committing offsets for tasks The interval at which to try committing offsets for tasks (defaults to 60000).
                      format: int64
                      maximum: 100000000
                      minimum: 1
                      type: integer
                    offset_flush_timeout_ms:
                      description: Offset flush timeout Maximum number of milliseconds to wait for records to flush and partition offset data to be committed to offset storage before cancelling the process and restoring the offset data to be committed in a future attempt (defaults to 5000).
                      format: int64
                      maximum: 2147483647
                      minimum: 1
                      type: integer
                    producer_max_request_size:
                      description: The maximum size of a request in bytes This setting will limit the number of record batches the producer will send in a single request to avoid sending huge requests.
                      format: int64
                      maximum: 10485760
                      minimum: 131072
                      type: integer
                    session_timeout_ms:
                      description: The timeout used to detect failures when using Kafka’s group management facilities The timeout in milliseconds used to detect failures when using Kafka’s group management facilities (defaults to 10000).
                      format: int64
                      maximum: 2147483647
                      minimum: 1
                      type: integer
                  type: object
                kafka_rest:
                  description: Enable Kafka-REST service
                  type: boolean
                kafka_rest_config:
                  description: Kafka REST configuration
                  properties:
                    consumer_enable_auto_commit:
                      description: consumer.enable.auto.commit If true the consumer's offset will be periodically committed to Kafka in the background
                      type: boolean
                    consumer_request_max_bytes:
                      description: consumer.request.max.bytes Maximum number of bytes in unencoded message keys and values by a single request
                      format: int64
                      maximum: 671088640
                      minimum: 0
                      type: integer
                    consumer_request_timeout_ms:
                      description: consumer.request.timeout.ms The maximum total time to wait for messages for a request if the maximum number of messages has not yet been reached
                      enum:
                      - 1000
                      - 15000
                      - 30000
                      format: int64
                      maximum: 30000
                      minimum: 1000
                      type: integer
                    custom_domain:
                      description: Custom domain Serve the web frontend using a custom CNAME pointing to the Aiven DNS name
                      maxLength: 255
                      type: string
                    producer_acks:
                      description: producer.acks The number of acknowledgments the producer requires the leader to have received before considering a request complete. If set to 'all' or '-1', the leader will wait for the full set of in-sync replicas to acknowledge the record.
                      enum:
                      - all
                      - "-1"
                      - 0
                      - 1
                      type: string
                    producer_linger_ms:
                      description: producer.linger.ms Wait for up to the given delay to allow batching records together
                      format: int64
                      maximum: 5000
                      minimum: 0
                      type: integer
                    public_access:
                      description: Allow access to selected service ports from the public Internet
                      properties:
                        kafka:
                          description: Allow clients to connect to kafka from the public internet for service nodes that are in a project VPC or another type of private network
                          type: boolean
                        kafka_connect:
                          description: Allow clients to connect to kafka_connect from the public internet for service nodes that are in a project VPC or another type of private network
                          type: boolean
                        kafka_rest:
                          description: Allow clients to connect to kafka_rest from the public internet for service nodes that are in a project VPC or another type of private network
                          type: boolean
                        prometheus:
                          description: Allow clients to connect to prometheus from the public internet for service nodes that are in a project VPC or another type of private network
                          type: boolean
                        schema_registry:
                          description: Allow clients to connect to schema_registry from the public internet for service nodes that are in a project VPC or another type of private network
                          type: boolean
                      type: object
                    simpleconsumer_pool_size_max:
                      description: simpleconsumer.pool.size.max Maximum number of SimpleConsumers that can be instantiated per broker
                      format: int64
                      maximum: 250
                      minimum: 10
                      type: integer
                  type: object
                kafka_version:
                  description: Kafka major version
                  enum:
                  - "1.0"
                  - "1.1"
                  - "2.0"
                  - "2.1"
                  - "2.2"
                  - "2.3"
                  - "2.4"
                  - "2.5"
                  - "2.6"
                  - "2.7"
                  type: string
                private_access:
                  description: Allow access to selected service ports from private networks
                  properties:
                    prometheus:
                      description: Allow clients to connect to prometheus with a DNS name that always resolves to the service's private IP addresses. Only available in certain network locations
                      type: boolean
                  type: object
                schema_registry:
                  description: Enable Schema-Registry service
                  type: boolean
                schema_registry_config:
                  description: Schema Registry configuration
                  properties:
                    leader_eligibility:
                      description: leader_eligibility If true, Karapace / Schema Registry on the service nodes can participate in leader election. It might be needed to disable this when the schemas topic is replicated to a secondary cluster and Karapace / Schema Registry there must not participate in leader election. Defaults to 'true'.
                      type: boolean
                    topic_name:
                      description: topic_name The durable single partition topic that acts as the durable log for the data. This topic must be compacted to avoid losing data due to retention policy. Please note that changing this configuration in an existing Schema Registry / Karapace setup leads to previous schemas being inaccessible, data encoded with them potentially unreadable and schema ID sequence put out of order. It's only possible to do the switch while Schema Registry / Karapace is disabled. Defaults to '_schemas'.
                      maxLength: 249
                      type: string
                  type: object
              type: object
            maintenance_window_dow:
              description: Day of week when maintenance operations should be performed. One monday, tuesday, wednesday, etc.
              enum:
              - monday
              - tuesday
              - wednesday
              - thursday
              - friday
              - saturday
              - sunday
              - never
              type: string
            maintenance_window_time:
              description: Time of day when maintenance operations should be performed. UTC time in HH:mm:ss format.
              maxLength: 8
              type: string
            plan:
              description: Subscription plan.
              maxLength: 128
              type: string
            project:
              description: Target project.
              format: ^[a-zA-Z0-9_-]*$
              maxLength: 63
              type: string
            project_vpc_id:
              description: Identifier of the VPC the service should be in, if any.
              maxLength: 36
              type: string
            service_name:
              description: Service name.
              maxLength: 63
              type: string
            state:
              description: Service state
              type: string
          required:
          - project
          - service_name
          - state
          type: object
      type: object
  version: v1alpha1
  versions:
  - name: v1alpha1
    served: true
    storage: true
status:
  acceptedNames:
    kind: ""
    plural: ""
  conditions: []
  storedVersions: []
