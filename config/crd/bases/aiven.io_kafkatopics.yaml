---
apiVersion: apiextensions.k8s.io/v1
kind: CustomResourceDefinition
metadata:
  annotations:
    controller-gen.kubebuilder.io/version: v0.15.0
  name: kafkatopics.aiven.io
spec:
  group: aiven.io
  names:
    kind: KafkaTopic
    listKind: KafkaTopicList
    plural: kafkatopics
    singular: kafkatopic
  scope: Namespaced
  versions:
    - additionalPrinterColumns:
        - jsonPath: .spec.serviceName
          name: Service Name
          type: string
        - jsonPath: .spec.project
          name: Project
          type: string
        - jsonPath: .spec.partitions
          name: Partitions
          type: string
        - jsonPath: .spec.replication
          name: Replication
          type: string
      name: v1alpha1
      schema:
        openAPIV3Schema:
          description: KafkaTopic is the Schema for the kafkatopics API
          properties:
            apiVersion:
              description: |-
                APIVersion defines the versioned schema of this representation of an object.
                Servers should convert recognized schemas to the latest internal value, and
                may reject unrecognized values.
                More info: https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#resources
              type: string
            kind:
              description: |-
                Kind is a string value representing the REST resource this object represents.
                Servers may infer this from the endpoint the client submits requests to.
                Cannot be updated.
                In CamelCase.
                More info: https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#types-kinds
              type: string
            metadata:
              type: object
            spec:
              description: KafkaTopicSpec defines the desired state of KafkaTopic
              properties:
                authSecretRef:
                  description: Authentication reference to Aiven token in a secret
                  properties:
                    key:
                      minLength: 1
                      type: string
                    name:
                      minLength: 1
                      type: string
                  required:
                    - key
                    - name
                  type: object
                config:
                  description: Kafka topic configuration
                  properties:
                    cleanup_policy:
                      description:
                        The retention policy to use on old segments. Possible
                        values include 'delete', 'compact', or a comma-separated list
                        of them. The default policy ('delete') will discard old segments
                        when their retention time or size limit has been reached. The
                        'compact' setting will enable log compaction on the topic.
                      type: string
                    compression_type:
                      description:
                        Specify the final compression type for a given topic.
                        This configuration accepts the standard compression codecs ('gzip',
                        'snappy', 'lz4', 'zstd'). It additionally accepts 'uncompressed'
                        which is equivalent to no compression; and 'producer' which
                        means retain the original compression codec set by the producer.
                      type: string
                    delete_retention_ms:
                      description:
                        The amount of time to retain delete tombstone markers
                        for log compacted topics. This setting also gives a bound on
                        the time in which a consumer must complete a read if they begin
                        from offset 0 to ensure that they get a valid snapshot of the
                        final stage (otherwise delete tombstones may be collected before
                        they complete their scan).
                      type: integer
                    file_delete_delay_ms:
                      description:
                        The time to wait before deleting a file from the
                        filesystem.
                      type: integer
                    flush_messages:
                      description:
                        This setting allows specifying an interval at which
                        we will force an fsync of data written to the log. For example
                        if this was set to 1 we would fsync after every message; if
                        it were 5 we would fsync after every five messages. In general
                        we recommend you not set this and use replication for durability
                        and allow the operating system's background flush capabilities
                        as it is more efficient.
                      type: integer
                    flush_ms:
                      description:
                        This setting allows specifying a time interval at
                        which we will force an fsync of data written to the log. For
                        example if this was set to 1000 we would fsync after 1000 ms
                        had passed. In general we recommend you not set this and use
                        replication for durability and allow the operating system's
                        background flush capabilities as it is more efficient.
                      type: integer
                    index_interval_bytes:
                      description:
                        This setting controls how frequently Kafka adds an
                        index entry to its offset index. The default setting ensures
                        that we index a message roughly every 4096 bytes. More indexing
                        allows reads to jump closer to the exact position in the log
                        but makes the index larger. You probably don't need to change
                        this.
                      type: integer
                    inkless_enable:
                      description: Indicates whether inkless should be enabled.
                      type: boolean
                    local_retention_bytes:
                      description:
                        This configuration controls the maximum bytes tiered
                        storage will retain segment files locally before it will discard
                        old log segments to free up space. If set to -2, the limit is
                        equal to overall retention time. If set to -1, no limit is applied
                        but it's possible only if overall retention is also -1.
                      type: integer
                    local_retention_ms:
                      description:
                        This configuration controls the maximum time tiered
                        storage will retain segment files locally before it will discard
                        old log segments to free up space. If set to -2, the time limit
                        is equal to overall retention time. If set to -1, no time limit
                        is applied but it's possible only if overall retention is also
                        -1.
                      type: integer
                    max_compaction_lag_ms:
                      description:
                        The maximum time a message will remain ineligible
                        for compaction in the log. Only applicable for logs that are
                        being compacted.
                      type: integer
                    max_message_bytes:
                      description:
                        The largest record batch size allowed by Kafka (after
                        compression if compression is enabled). If this is increased
                        and there are consumers older than 0.10.2, the consumers' fetch
                        size must also be increased so that the they can fetch record
                        batches this large. In the latest message format version, records
                        are always grouped into batches for efficiency. In previous
                        message format versions, uncompressed records are not grouped
                        into batches and this limit only applies to a single record
                        in that case.
                      type: integer
                    message_downconversion_enable:
                      description:
                        This configuration controls whether down-conversion
                        of message formats is enabled to satisfy consume requests. When
                        set to false, broker will not perform down-conversion for consumers
                        expecting an older message format. The broker responds with
                        UNSUPPORTED_VERSION error for consume requests from such older
                        clients. This configuration does not apply to any message format
                        conversion that might be required for replication to followers.
                      type: boolean
                    message_format_version:
                      description:
                        "Specify the message format version the broker will
                        use to append messages to the logs. The value should be a valid
                        ApiVersion. Some examples are: 0.8.2, 0.9.0.0, 0.10.0, check
                        ApiVersion for more details. By setting a particular message
                        format version, the user is certifying that all the existing
                        messages on disk are smaller or equal than the specified version.
                        Setting this value incorrectly will cause consumers with older
                        versions to break as they will receive messages with a format
                        that they don't understand."
                      type: string
                    message_timestamp_difference_max_ms:
                      description:
                        The maximum difference allowed between the timestamp
                        when a broker receives a message and the timestamp specified
                        in the message. If message.timestamp.type=CreateTime, a message
                        will be rejected if the difference in timestamp exceeds this
                        threshold. This configuration is ignored if message.timestamp.type=LogAppendTime.
                      type: integer
                    message_timestamp_type:
                      description:
                        Define whether the timestamp in the message is message
                        create time or log append time.
                      type: string
                    min_cleanable_dirty_ratio:
                      description:
                        "This configuration controls how frequently the log
                        compactor will attempt to clean the log (assuming log compaction
                        is enabled). By default we will avoid cleaning a log where more
                        than 50% of the log has been compacted. This ratio bounds the
                        maximum space wasted in the log by duplicates (at 50% at most
                        50% of the log could be duplicates). A higher ratio will mean
                        fewer, more efficient cleanings but will mean more wasted space
                        in the log. If the max.compaction.lag.ms or the min.compaction.lag.ms
                        configurations are also specified, then the log compactor considers
                        the log to be eligible for compaction as soon as either: (i)
                        the dirty ratio threshold has been met and the log has had dirty
                        (uncompacted) records for at least the min.compaction.lag.ms
                        duration, or (ii) if the log has had dirty (uncompacted) records
                        for at most the max.compaction.lag.ms period."
                      type: number
                    min_compaction_lag_ms:
                      description:
                        The minimum time a message will remain uncompacted
                        in the log. Only applicable for logs that are being compacted.
                      type: integer
                    min_insync_replicas:
                      description:
                        When a producer sets acks to 'all' (or '-1'), this
                        configuration specifies the minimum number of replicas that
                        must acknowledge a write for the write to be considered successful.
                        If this minimum cannot be met, then the producer will raise
                        an exception (either NotEnoughReplicas or NotEnoughReplicasAfterAppend).
                        When used together, min.insync.replicas and acks allow you to
                        enforce greater durability guarantees. A typical scenario would
                        be to create a topic with a replication factor of 3, set min.insync.replicas
                        to 2, and produce with acks of 'all'. This will ensure that
                        the producer raises an exception if a majority of replicas do
                        not receive a write.
                      type: integer
                    preallocate:
                      description:
                        True if we should preallocate the file on disk when
                        creating a new log segment.
                      type: boolean
                    remote_storage_enable:
                      description: Indicates whether tiered storage should be enabled.
                      type: boolean
                    retention_bytes:
                      description:
                        This configuration controls the maximum size a partition
                        (which consists of log segments) can grow to before we will
                        discard old log segments to free up space if we are using the
                        'delete' retention policy. By default there is no size limit
                        only a time limit. Since this limit is enforced at the partition
                        level, multiply it by the number of partitions to compute the
                        topic retention in bytes.
                      type: integer
                    retention_ms:
                      description:
                        This configuration controls the maximum time we will
                        retain a log before we will discard old log segments to free
                        up space if we are using the 'delete' retention policy. This
                        represents an SLA on how soon consumers must read their data.
                        If set to -1, no time limit is applied.
                      type: integer
                    segment_bytes:
                      description:
                        This configuration controls the segment file size
                        for the log. Retention and cleaning is always done a file at
                        a time so a larger segment size means fewer files but less granular
                        control over retention. Setting this to a very low value has
                        consequences, and the Aiven management plane ignores values
                        less than 10 megabytes.
                      type: integer
                    segment_index_bytes:
                      description:
                        This configuration controls the size of the index
                        that maps offsets to file positions. We preallocate this index
                        file and shrink it only after log rolls. You generally should
                        not need to change this setting.
                      type: integer
                    segment_jitter_ms:
                      description:
                        The maximum random jitter subtracted from the scheduled
                        segment roll time to avoid thundering herds of segment rolling
                      type: integer
                    segment_ms:
                      description:
                        This configuration controls the period of time after
                        which Kafka will force the log to roll even if the segment file
                        isn't full to ensure that retention can delete or compact old
                        data. Setting this to a very low value has consequences, and
                        the Aiven management plane ignores values less than 10 seconds.
                      type: integer
                    unclean_leader_election_enable:
                      description:
                        Indicates whether to enable replicas not in the ISR
                        set to be elected as leader as a last resort, even though doing
                        so may result in data loss.
                      type: boolean
                  type: object
                partitions:
                  description: Number of partitions to create in the topic
                  maximum: 1000000
                  minimum: 1
                  type: integer
                project:
                  description: Identifies the project this resource belongs to
                  maxLength: 63
                  pattern: ^[a-zA-Z0-9_-]+$
                  type: string
                  x-kubernetes-validations:
                    - message: Value is immutable
                      rule: self == oldSelf
                replication:
                  description: Replication factor for the topic
                  minimum: 2
                  type: integer
                serviceName:
                  description:
                    Specifies the name of the service that this resource
                    belongs to
                  maxLength: 63
                  pattern: ^[a-z][-a-z0-9]+$
                  type: string
                  x-kubernetes-validations:
                    - message: Value is immutable
                      rule: self == oldSelf
                tags:
                  description: Kafka topic tags
                  items:
                    properties:
                      key:
                        maxLength: 64
                        minLength: 1
                        pattern: ^[a-zA-Z0-9_-]+$
                        type: string
                      value:
                        maxLength: 256
                        pattern: ^[a-zA-Z0-9_-]+$
                        type: string
                    required:
                      - key
                    type: object
                  type: array
                termination_protection:
                  description: |-
                    It is a Kubernetes side deletion protections, which prevents the kafka topic
                    from being deleted by Kubernetes. It is recommended to enable this for any production
                    databases containing critical data.
                  type: boolean
                topicName:
                  description: |-
                    Topic name. If provided, is used instead of metadata.name.
                    This field supports additional characters, has a longer length,
                    and will replace metadata.name in future releases
                  maxLength: 249
                  minLength: 1
                  type: string
                  x-kubernetes-validations:
                    - message: Value is immutable
                      rule: self == oldSelf
              required:
                - partitions
                - project
                - replication
                - serviceName
              type: object
            status:
              description: KafkaTopicStatus defines the observed state of KafkaTopic
              properties:
                conditions:
                  description:
                    Conditions represent the latest available observations
                    of an KafkaTopic state
                  items:
                    description:
                      "Condition contains details for one aspect of the current
                      state of this API Resource.\n---\nThis struct is intended for
                      direct use as an array at the field path .status.conditions.  For
                      example,\n\n\n\ttype FooStatus struct{\n\t    // Represents the
                      observations of a foo's current state.\n\t    // Known .status.conditions.type
                      are: \"Available\", \"Progressing\", and \"Degraded\"\n\t    //
                      +patchMergeKey=type\n\t    // +patchStrategy=merge\n\t    // +listType=map\n\t
                      \   // +listMapKey=type\n\t    Conditions []metav1.Condition `json:\"conditions,omitempty\"
                      patchStrategy:\"merge\" patchMergeKey:\"type\" protobuf:\"bytes,1,rep,name=conditions\"`\n\n\n\t
                      \   // other fields\n\t}"
                    properties:
                      lastTransitionTime:
                        description: |-
                          lastTransitionTime is the last time the condition transitioned from one status to another.
                          This should be when the underlying condition changed.  If that is not known, then using the time when the API field changed is acceptable.
                        format: date-time
                        type: string
                      message:
                        description: |-
                          message is a human readable message indicating details about the transition.
                          This may be an empty string.
                        maxLength: 32768
                        type: string
                      observedGeneration:
                        description: |-
                          observedGeneration represents the .metadata.generation that the condition was set based upon.
                          For instance, if .metadata.generation is currently 12, but the .status.conditions[x].observedGeneration is 9, the condition is out of date
                          with respect to the current state of the instance.
                        format: int64
                        minimum: 0
                        type: integer
                      reason:
                        description: |-
                          reason contains a programmatic identifier indicating the reason for the condition's last transition.
                          Producers of specific condition types may define expected values and meanings for this field,
                          and whether the values are considered a guaranteed API.
                          The value should be a CamelCase string.
                          This field may not be empty.
                        maxLength: 1024
                        minLength: 1
                        pattern: ^[A-Za-z]([A-Za-z0-9_,:]*[A-Za-z0-9_])?$
                        type: string
                      status:
                        description: status of the condition, one of True, False, Unknown.
                        enum:
                          - "True"
                          - "False"
                          - Unknown
                        type: string
                      type:
                        description: |-
                          type of condition in CamelCase or in foo.example.com/CamelCase.
                          ---
                          Many .condition.type values are consistent across resources like Available, but because arbitrary conditions can be
                          useful (see .node.status.conditions), the ability to deconflict is important.
                          The regex it matches is (dns1123SubdomainFmt/)?(qualifiedNameFmt)
                        maxLength: 316
                        pattern: ^([a-z0-9]([-a-z0-9]*[a-z0-9])?(\.[a-z0-9]([-a-z0-9]*[a-z0-9])?)*/)?(([A-Za-z0-9][-A-Za-z0-9_.]*)?[A-Za-z0-9])$
                        type: string
                    required:
                      - lastTransitionTime
                      - message
                      - reason
                      - status
                      - type
                    type: object
                  type: array
                state:
                  description: State represents the state of the kafka topic
                  type: string
              required:
                - conditions
                - state
              type: object
          type: object
      served: true
      storage: true
      subresources:
        status: {}
